{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%matplotlib nbagg\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "\n",
    "import data\n",
    "import utils\n",
    "import custom_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "\n",
    "reset_default_graph()\n",
    "\n",
    "# Defining model\n",
    "num_iterations = 3e4\n",
    "batch_size=64\n",
    "number_inputs=42\n",
    "number_outputs=8\n",
    "seq_len=30 # max 700\n",
    "learning_rate = 0.001\n",
    "\n",
    "X_input = tf.placeholder(tf.float32, shape=[None, None, number_inputs], name='X_input')\n",
    "X_length = tf.placeholder(tf.int32, shape=[None,], name='X_length')\n",
    "t_input = tf.placeholder(tf.int32, shape=[None, None], name='t_input')\n",
    "t_mask = tf.placeholder(tf.float32, shape=[None, None], name='t_mask')\n",
    "\n",
    "num_units_encoder = 100\n",
    "num_units_l1 = 100\n",
    "\n",
    "cell_fw = tf.nn.rnn_cell.GRUCell(num_units_encoder)\n",
    "cell_bw = tf.nn.rnn_cell.GRUCell(num_units_encoder)\n",
    "#enc_cell = tf.nn.rnn_cell.OutputProjectionWrapper(enc_cell, number_outputs)\n",
    "enc_outputs, _ = tf.nn.bidirectional_dynamic_rnn(cell_fw=cell_fw, cell_bw=cell_bw, inputs=X_input,\n",
    "                                                 sequence_length=X_length, dtype=tf.float32)\n",
    "enc_outputs = tf.concat(2, enc_outputs)\n",
    "outputs = tf.reshape(enc_outputs, [-1, num_units_encoder*2])\n",
    "l1 = fully_connected(outputs, num_units_l1, normalizer_fn=batch_norm)\n",
    "l_out = fully_connected(l1, number_outputs, activation_fn=None)\n",
    "\n",
    "batch_size_shp = tf.shape(enc_outputs)[0]\n",
    "seq_len_shp = tf.shape(enc_outputs)[1]\n",
    "l_out_reshape = tf.reshape(l_out, [batch_size_shp, seq_len_shp, number_outputs])\n",
    "\n",
    "y = l_out_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_and_acc(preds):\n",
    "    # sequence_loss_tensor is a modification of TensorFlow's own sequence_to_sequence_loss\n",
    "    # TensorFlow's seq2seq loss works with a 2D list instead of a 3D tensors\n",
    "    loss = custom_ops.sequence_loss(preds, t_input, t_mask)\n",
    "    # if you want regularization\n",
    "    #reg_scale = 0.00001\n",
    "    #regularize = tf.contrib.layers.l2_regularizer(reg_scale)\n",
    "    #params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    #reg_term = sum([regularize(param) for param in params])\n",
    "    #loss += reg_term\n",
    "    # calculate accuracy\n",
    "    argmax = tf.to_int32(tf.argmax(preds, 2))\n",
    "    correct = tf.to_float(tf.equal(argmax, t_input)) * t_mask\n",
    "    accuracy = tf.reduce_sum(correct) / tf.reduce_sum(t_mask)\n",
    "    return loss, accuracy, argmax\n",
    "\n",
    "loss, accuracy, predictions = loss_and_acc(y)\n",
    "\n",
    "# use lobal step to keep track of our iterations\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "# pick optimizer, try momentum or adadelta\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# extract gradients for each variable\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "# add below for clipping by norm\n",
    "#gradients, variables = zip(*grads_and_vars)  # unzip list of tuples\n",
    "#clipped_gradients, global_norm = (\n",
    "#    tf.clip_by_global_norm(gradients, self.clip_norm) )\n",
    "#grads_and_vars = zip(clipped_gradients, variables)\n",
    "# apply gradients and make trainable function\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, t_train, t_valid, mask_train, mask_valid, length_train, length_valid, num_seq_train =\\\n",
    "data.get_train(seq_len)\n",
    "print(\"X_train,\", X_train.shape, X_train.dtype)\n",
    "print(\"t_train,\", t_train.shape, t_train.dtype)\n",
    "print(\"mask_train,\", mask_train.shape, mask_train.dtype)\n",
    "print(\"length_train,\", length_train.shape, length_train.dtype)\n",
    "print(\"num_seq_train\", num_seq_train)\n",
    "print(\"X_valid,\", X_valid.shape, X_valid.dtype)\n",
    "print(\"t_valid,\", t_valid.shape, t_valid.dtype)\n",
    "print(\"mask_valid,\", mask_valid.shape, mask_valid.dtype)\n",
    "print(\"length_valid,\", length_valid.shape, length_valid.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)\n",
    "# initialize the Session\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))\n",
    "# test train part\n",
    "sess.run(tf.initialize_all_variables())\n",
    "feed_dict = {X_input: X_valid, X_length: length_valid, t_input: t_valid,\n",
    "             t_mask: mask_valid}\n",
    "fetches = [y]\n",
    "res = sess.run(fetches=fetches, feed_dict=feed_dict)\n",
    "print \"y\", res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(X, t, mask, length):\n",
    "    num_sequences = X.shape[0]\n",
    "    seq_names = np.arange(0,num_sequences)\n",
    "    np.random.shuffle(seq_names)\n",
    "    X = X_train[seq_names]\n",
    "    t = t[seq_names]\n",
    "    mask = mask[seq_names]\n",
    "    length = length[seq_names]\n",
    "    return X, t, mask, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up running parameters\n",
    "val_interval = batch_size*2\n",
    "samples_to_process = 1e5\n",
    "samples_processed = 0\n",
    "num_samples_per_epoch = int(num_seq_train/batch_size)\n",
    "samples_val = []\n",
    "costs, accs_val = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        #if (num_samples_per_epoch % samples) == 0:\n",
    "        #    print(\"shuffling data ...\")\n",
    "        #    X_train, t_train, mask_train, length_train = shuffle_data(\n",
    "        #        X_train, t_train, mask_train, length_train)\n",
    "        # make fetches\n",
    "        fetches_tr = [train_op, loss, accuracy]\n",
    "        # set up feed dict\n",
    "        feed_dict_tr = {X_input: X_train, X_length: length_train,\n",
    "                        t_input: t_train, t_mask: mask_train}\n",
    "        # run the model\n",
    "        res = tuple(sess.run(fetches=fetches_tr, feed_dict=feed_dict_tr))\n",
    "        _, batch_cost, batch_acc = res\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += batch_size\n",
    "        #print(\"samples_processed,\", samples_processed)\n",
    "        #print(\"batch_cost,\", batch_cost)\n",
    "        #if samples_processed % 1000 == 0: print batch_cost, batch_acc\n",
    "        #validation data\n",
    "        if samples_processed % val_interval == 0:\n",
    "            print \"validating\"\n",
    "            fetches_val = [accuracy, y]\n",
    "            feed_dict_val = {X_input: X_valid, X_length: length_valid, t_input: t_valid,\n",
    "                             t_mask: mask_valid}\n",
    "            res = tuple(sess.run(fetches=fetches_val, feed_dict=feed_dict_val))\n",
    "            acc_val, output_val = res\n",
    "            samples_val += [samples_processed]\n",
    "            accs_val += [acc_val]\n",
    "            #print(\"validation_accs\", acc_val)\n",
    "            plt.plot(samples_val, accs_val, 'g-')\n",
    "            plt.ylabel('Validation Accuracy', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            plt.savefig(\"out.png\")\n",
    "            display.display(display.Image(filename=\"out.png\"))\n",
    "            display.clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
